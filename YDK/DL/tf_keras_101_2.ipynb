{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### tf.keras Practice!\n",
        "\n",
        "- CIFAR10 이미지 데이터셋을 분류하는 문제를 풀어봅니다!"
      ],
      "metadata": {
        "id": "ZCxzMUXtyuKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckiJ3GrvvD_Y",
        "outputId": "d8a6bb56-a859-4a83-d894-0c43c49d99b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 30 05:57:32 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZdJiqcQMymOG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fd108551-c8bc-4e32-c2d1-ec961efdc1f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "# datasets\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras import Sequential"
      ],
      "metadata": {
        "id": "9wbosILfLDe1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load CIFAR10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "## RGB (3-channel)\n",
        "# 32 x 32 - R -> pixel matrix\n",
        "# 32 x 32 - G\n",
        "# 32 x 32 - B"
      ],
      "metadata": {
        "id": "kGlnoGn0LcGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007ef045-bd1c-4f03-9c7d-fefddc1b5fd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "\n",
        "1. model architecture\n",
        "\n",
        "- Hidden Layer (뒤로 갈수록 hidden node수가 작아짐)\n",
        "\n",
        "- Activation function : 'sigmoid' / 'relu'\n",
        "\n",
        "\n",
        "\n",
        "2. loss optimization\n",
        "\n",
        "\n",
        "- optimizer : 'sgd', 'momentum', 'adam'\n",
        "\n",
        "- batch_size : 1 -> 8-> 32 -> 64 -> 128 -> 256 -> 512 -> 2048 -> ...\n",
        "\n",
        "- epochs : 10 -> 30 -> 100 -> 10000 (overfitting) "
      ],
      "metadata": {
        "id": "-0jeg5VVey-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(32, 32, 3)),\n",
        "    Flatten(),  # 32x32x3 ---> 3072  (input layer의 node 수)\n",
        "    Dense(units=1024, activation='relu'),\n",
        "    Dense(units=512, activation='relu'),\n",
        "    Dense(units=256, activation='relu'),\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=16, activation='relu'),\n",
        "    Dense(units=10, activation='softmax') # output layer\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "KMqmYoDXQjw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39480203-18eb-4e9e-d7d0-bc58348d2a32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              3146752   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,846,810\n",
            "Trainable params: 3,846,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train # 0 ~ 9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsddIg_d2ayo",
        "outputId": "5c3af90d-f196-4215-e824-225ba1eabeb7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "lr = 1e-4\n",
        "epochs = 200\n",
        "batch_size = 128\n",
        "# 모든 데이터가 학습에 다 사용되면 1 epoch.\n",
        "# epochs : 전체 데이터를 몇번 반복 학습을 수행할건지.\n",
        "# iterations : 실제로 weight update를 한 횟수.\n",
        "\n",
        "loss_fn = 'sparse_categorical_crossentropy' # target vector가 정수인 경우.\n",
        "#optimizer = SGD(learning_rate=lr) # learning rate 조절을 위해서 보통 함수로 구현.\n",
        "#optimizer = SGD(learning_rate=lr, momentum=0.9) # Momentum optimizer\n",
        "optimizer = Adam(learning_rate=lr) # Adam optimizer\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YaBGCB67Uunb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit\n",
        "model.fit(x=X_train,\n",
        "          y=y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=2,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN-gOEGLtkuB",
        "outputId": "d2e1c1c4-9297-4816-b810-2446d41fde11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "391/391 - 3s - loss: 3.2410 - accuracy: 0.1700 - val_loss: 2.1638 - val_accuracy: 0.2188 - 3s/epoch - 9ms/step\n",
            "Epoch 2/200\n",
            "391/391 - 3s - loss: 2.1393 - accuracy: 0.2302 - val_loss: 2.0876 - val_accuracy: 0.2579 - 3s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "391/391 - 1s - loss: 2.0454 - accuracy: 0.2750 - val_loss: 2.0097 - val_accuracy: 0.2846 - 1s/epoch - 4ms/step\n",
            "Epoch 4/200\n",
            "391/391 - 2s - loss: 1.9606 - accuracy: 0.3122 - val_loss: 1.9134 - val_accuracy: 0.3231 - 2s/epoch - 4ms/step\n",
            "Epoch 5/200\n",
            "391/391 - 1s - loss: 1.8933 - accuracy: 0.3419 - val_loss: 1.8593 - val_accuracy: 0.3478 - 1s/epoch - 4ms/step\n",
            "Epoch 6/200\n",
            "391/391 - 1s - loss: 1.8241 - accuracy: 0.3613 - val_loss: 1.8148 - val_accuracy: 0.3705 - 1s/epoch - 4ms/step\n",
            "Epoch 7/200\n",
            "391/391 - 2s - loss: 1.7677 - accuracy: 0.3818 - val_loss: 1.7899 - val_accuracy: 0.3746 - 2s/epoch - 4ms/step\n",
            "Epoch 8/200\n",
            "391/391 - 1s - loss: 1.7259 - accuracy: 0.3951 - val_loss: 1.7926 - val_accuracy: 0.3844 - 1s/epoch - 4ms/step\n",
            "Epoch 9/200\n",
            "391/391 - 1s - loss: 1.6820 - accuracy: 0.4107 - val_loss: 1.6787 - val_accuracy: 0.4177 - 1s/epoch - 4ms/step\n",
            "Epoch 10/200\n",
            "391/391 - 1s - loss: 1.6439 - accuracy: 0.4211 - val_loss: 1.6609 - val_accuracy: 0.4126 - 1s/epoch - 4ms/step\n",
            "Epoch 11/200\n",
            "391/391 - 2s - loss: 1.6009 - accuracy: 0.4365 - val_loss: 1.6578 - val_accuracy: 0.4283 - 2s/epoch - 4ms/step\n",
            "Epoch 12/200\n",
            "391/391 - 1s - loss: 1.5740 - accuracy: 0.4438 - val_loss: 1.6667 - val_accuracy: 0.4176 - 1s/epoch - 4ms/step\n",
            "Epoch 13/200\n",
            "391/391 - 1s - loss: 1.5523 - accuracy: 0.4511 - val_loss: 1.6376 - val_accuracy: 0.4270 - 1s/epoch - 4ms/step\n",
            "Epoch 14/200\n",
            "391/391 - 1s - loss: 1.5166 - accuracy: 0.4654 - val_loss: 1.6583 - val_accuracy: 0.4269 - 1s/epoch - 4ms/step\n",
            "Epoch 15/200\n",
            "391/391 - 2s - loss: 1.4814 - accuracy: 0.4761 - val_loss: 1.6500 - val_accuracy: 0.4283 - 2s/epoch - 4ms/step\n",
            "Epoch 16/200\n",
            "391/391 - 1s - loss: 1.4597 - accuracy: 0.4825 - val_loss: 1.5819 - val_accuracy: 0.4507 - 1s/epoch - 4ms/step\n",
            "Epoch 17/200\n",
            "391/391 - 1s - loss: 1.4300 - accuracy: 0.4928 - val_loss: 1.5435 - val_accuracy: 0.4635 - 1s/epoch - 4ms/step\n",
            "Epoch 18/200\n",
            "391/391 - 2s - loss: 1.4055 - accuracy: 0.5014 - val_loss: 1.5205 - val_accuracy: 0.4698 - 2s/epoch - 4ms/step\n",
            "Epoch 19/200\n",
            "391/391 - 1s - loss: 1.3809 - accuracy: 0.5120 - val_loss: 1.5614 - val_accuracy: 0.4605 - 1s/epoch - 4ms/step\n",
            "Epoch 20/200\n",
            "391/391 - 2s - loss: 1.3589 - accuracy: 0.5186 - val_loss: 1.5158 - val_accuracy: 0.4734 - 2s/epoch - 4ms/step\n",
            "Epoch 21/200\n",
            "391/391 - 2s - loss: 1.3328 - accuracy: 0.5279 - val_loss: 1.5238 - val_accuracy: 0.4690 - 2s/epoch - 4ms/step\n",
            "Epoch 22/200\n",
            "391/391 - 1s - loss: 1.3005 - accuracy: 0.5362 - val_loss: 1.5204 - val_accuracy: 0.4728 - 1s/epoch - 4ms/step\n",
            "Epoch 23/200\n",
            "391/391 - 1s - loss: 1.2811 - accuracy: 0.5426 - val_loss: 1.4630 - val_accuracy: 0.4953 - 1s/epoch - 4ms/step\n",
            "Epoch 24/200\n",
            "391/391 - 1s - loss: 1.2541 - accuracy: 0.5547 - val_loss: 1.5109 - val_accuracy: 0.4810 - 1s/epoch - 4ms/step\n",
            "Epoch 25/200\n",
            "391/391 - 2s - loss: 1.2272 - accuracy: 0.5648 - val_loss: 1.4865 - val_accuracy: 0.4911 - 2s/epoch - 4ms/step\n",
            "Epoch 26/200\n",
            "391/391 - 2s - loss: 1.2061 - accuracy: 0.5694 - val_loss: 1.4772 - val_accuracy: 0.5014 - 2s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "391/391 - 1s - loss: 1.1744 - accuracy: 0.5810 - val_loss: 1.4853 - val_accuracy: 0.5011 - 1s/epoch - 4ms/step\n",
            "Epoch 28/200\n",
            "391/391 - 1s - loss: 1.1555 - accuracy: 0.5879 - val_loss: 1.5038 - val_accuracy: 0.4909 - 1s/epoch - 4ms/step\n",
            "Epoch 29/200\n",
            "391/391 - 1s - loss: 1.1336 - accuracy: 0.5975 - val_loss: 1.4697 - val_accuracy: 0.5052 - 1s/epoch - 4ms/step\n",
            "Epoch 30/200\n",
            "391/391 - 1s - loss: 1.0971 - accuracy: 0.6087 - val_loss: 1.5015 - val_accuracy: 0.5040 - 1s/epoch - 4ms/step\n",
            "Epoch 31/200\n",
            "391/391 - 2s - loss: 1.0672 - accuracy: 0.6208 - val_loss: 1.5135 - val_accuracy: 0.5007 - 2s/epoch - 4ms/step\n",
            "Epoch 32/200\n",
            "391/391 - 2s - loss: 1.0561 - accuracy: 0.6235 - val_loss: 1.5439 - val_accuracy: 0.4919 - 2s/epoch - 4ms/step\n",
            "Epoch 33/200\n",
            "391/391 - 1s - loss: 1.0221 - accuracy: 0.6344 - val_loss: 1.5303 - val_accuracy: 0.5077 - 1s/epoch - 4ms/step\n",
            "Epoch 34/200\n",
            "391/391 - 1s - loss: 1.0031 - accuracy: 0.6430 - val_loss: 1.4926 - val_accuracy: 0.5157 - 1s/epoch - 4ms/step\n",
            "Epoch 35/200\n",
            "391/391 - 2s - loss: 0.9761 - accuracy: 0.6542 - val_loss: 1.5846 - val_accuracy: 0.4903 - 2s/epoch - 4ms/step\n",
            "Epoch 36/200\n",
            "391/391 - 1s - loss: 0.9507 - accuracy: 0.6601 - val_loss: 1.5240 - val_accuracy: 0.5128 - 1s/epoch - 4ms/step\n",
            "Epoch 37/200\n",
            "391/391 - 1s - loss: 0.9135 - accuracy: 0.6773 - val_loss: 1.5631 - val_accuracy: 0.4984 - 1s/epoch - 4ms/step\n",
            "Epoch 38/200\n",
            "391/391 - 1s - loss: 0.8980 - accuracy: 0.6809 - val_loss: 1.5493 - val_accuracy: 0.5136 - 1s/epoch - 4ms/step\n",
            "Epoch 39/200\n",
            "391/391 - 2s - loss: 0.8759 - accuracy: 0.6890 - val_loss: 1.6012 - val_accuracy: 0.5092 - 2s/epoch - 4ms/step\n",
            "Epoch 40/200\n",
            "391/391 - 2s - loss: 0.8572 - accuracy: 0.6931 - val_loss: 1.5960 - val_accuracy: 0.5162 - 2s/epoch - 4ms/step\n",
            "Epoch 41/200\n",
            "391/391 - 1s - loss: 0.8253 - accuracy: 0.7071 - val_loss: 1.6293 - val_accuracy: 0.5079 - 1s/epoch - 4ms/step\n",
            "Epoch 42/200\n",
            "391/391 - 2s - loss: 0.8031 - accuracy: 0.7157 - val_loss: 1.6417 - val_accuracy: 0.5219 - 2s/epoch - 4ms/step\n",
            "Epoch 43/200\n",
            "391/391 - 2s - loss: 0.7740 - accuracy: 0.7256 - val_loss: 1.6953 - val_accuracy: 0.5023 - 2s/epoch - 4ms/step\n",
            "Epoch 44/200\n",
            "391/391 - 1s - loss: 0.7586 - accuracy: 0.7302 - val_loss: 1.6817 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
            "Epoch 45/200\n",
            "391/391 - 1s - loss: 0.7385 - accuracy: 0.7373 - val_loss: 1.7287 - val_accuracy: 0.5100 - 1s/epoch - 4ms/step\n",
            "Epoch 46/200\n",
            "391/391 - 1s - loss: 0.7181 - accuracy: 0.7458 - val_loss: 1.7432 - val_accuracy: 0.5116 - 1s/epoch - 4ms/step\n",
            "Epoch 47/200\n",
            "391/391 - 2s - loss: 0.6913 - accuracy: 0.7543 - val_loss: 1.7564 - val_accuracy: 0.5180 - 2s/epoch - 4ms/step\n",
            "Epoch 48/200\n",
            "391/391 - 2s - loss: 0.6642 - accuracy: 0.7646 - val_loss: 1.8204 - val_accuracy: 0.5139 - 2s/epoch - 4ms/step\n",
            "Epoch 49/200\n",
            "391/391 - 2s - loss: 0.6487 - accuracy: 0.7696 - val_loss: 1.7887 - val_accuracy: 0.5149 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "391/391 - 2s - loss: 0.6267 - accuracy: 0.7779 - val_loss: 1.8600 - val_accuracy: 0.5139 - 2s/epoch - 4ms/step\n",
            "Epoch 51/200\n",
            "391/391 - 1s - loss: 0.6092 - accuracy: 0.7850 - val_loss: 1.8629 - val_accuracy: 0.5139 - 1s/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "391/391 - 1s - loss: 0.5818 - accuracy: 0.7950 - val_loss: 1.9465 - val_accuracy: 0.5143 - 1s/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "391/391 - 1s - loss: 0.5667 - accuracy: 0.7982 - val_loss: 1.9711 - val_accuracy: 0.5119 - 1s/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "391/391 - 2s - loss: 0.5536 - accuracy: 0.8020 - val_loss: 2.0043 - val_accuracy: 0.5065 - 2s/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "391/391 - 1s - loss: 0.5324 - accuracy: 0.8121 - val_loss: 2.0628 - val_accuracy: 0.5196 - 1s/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "391/391 - 2s - loss: 0.5229 - accuracy: 0.8144 - val_loss: 2.0499 - val_accuracy: 0.5061 - 2s/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "391/391 - 1s - loss: 0.4983 - accuracy: 0.8221 - val_loss: 2.1037 - val_accuracy: 0.5204 - 1s/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "391/391 - 1s - loss: 0.4776 - accuracy: 0.8305 - val_loss: 2.1776 - val_accuracy: 0.5080 - 1s/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "391/391 - 1s - loss: 0.4738 - accuracy: 0.8323 - val_loss: 2.1605 - val_accuracy: 0.5094 - 1s/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "391/391 - 1s - loss: 0.4577 - accuracy: 0.8353 - val_loss: 2.2973 - val_accuracy: 0.5042 - 1s/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "391/391 - 1s - loss: 0.4488 - accuracy: 0.8406 - val_loss: 2.2387 - val_accuracy: 0.5181 - 1s/epoch - 3ms/step\n",
            "Epoch 62/200\n",
            "391/391 - 1s - loss: 0.4300 - accuracy: 0.8478 - val_loss: 2.3019 - val_accuracy: 0.5172 - 1s/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "391/391 - 1s - loss: 0.4184 - accuracy: 0.8502 - val_loss: 2.3227 - val_accuracy: 0.5174 - 1s/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "391/391 - 2s - loss: 0.3977 - accuracy: 0.8595 - val_loss: 2.4267 - val_accuracy: 0.5126 - 2s/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "391/391 - 1s - loss: 0.3893 - accuracy: 0.8618 - val_loss: 2.5740 - val_accuracy: 0.4988 - 1s/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "391/391 - 1s - loss: 0.3781 - accuracy: 0.8666 - val_loss: 2.5292 - val_accuracy: 0.5065 - 1s/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "391/391 - 2s - loss: 0.3586 - accuracy: 0.8725 - val_loss: 2.5646 - val_accuracy: 0.5035 - 2s/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "391/391 - 1s - loss: 0.3678 - accuracy: 0.8694 - val_loss: 2.5475 - val_accuracy: 0.5114 - 1s/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "391/391 - 1s - loss: 0.3501 - accuracy: 0.8761 - val_loss: 2.6592 - val_accuracy: 0.5129 - 1s/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "391/391 - 2s - loss: 0.3293 - accuracy: 0.8823 - val_loss: 2.6378 - val_accuracy: 0.5130 - 2s/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "391/391 - 2s - loss: 0.3483 - accuracy: 0.8769 - val_loss: 2.6391 - val_accuracy: 0.5156 - 2s/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "391/391 - 2s - loss: 0.3233 - accuracy: 0.8875 - val_loss: 2.6900 - val_accuracy: 0.5085 - 2s/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "391/391 - 1s - loss: 0.3022 - accuracy: 0.8925 - val_loss: 2.7743 - val_accuracy: 0.5033 - 1s/epoch - 3ms/step\n",
            "Epoch 74/200\n",
            "391/391 - 1s - loss: 0.3111 - accuracy: 0.8909 - val_loss: 2.7155 - val_accuracy: 0.5117 - 1s/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "391/391 - 1s - loss: 0.2874 - accuracy: 0.8976 - val_loss: 2.8779 - val_accuracy: 0.5100 - 1s/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "391/391 - 2s - loss: 0.2892 - accuracy: 0.8975 - val_loss: 2.8728 - val_accuracy: 0.5112 - 2s/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "391/391 - 1s - loss: 0.2723 - accuracy: 0.9040 - val_loss: 2.9220 - val_accuracy: 0.5142 - 1s/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "391/391 - 2s - loss: 0.2730 - accuracy: 0.9030 - val_loss: 3.0925 - val_accuracy: 0.4978 - 2s/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "391/391 - 1s - loss: 0.2795 - accuracy: 0.9033 - val_loss: 2.9323 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "391/391 - 1s - loss: 0.2787 - accuracy: 0.9026 - val_loss: 3.0023 - val_accuracy: 0.5078 - 1s/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "391/391 - 2s - loss: 0.2392 - accuracy: 0.9160 - val_loss: 3.1435 - val_accuracy: 0.5088 - 2s/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "391/391 - 2s - loss: 0.2400 - accuracy: 0.9164 - val_loss: 3.1326 - val_accuracy: 0.5092 - 2s/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "391/391 - 2s - loss: 0.2211 - accuracy: 0.9233 - val_loss: 3.2661 - val_accuracy: 0.5040 - 2s/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "391/391 - 2s - loss: 0.2636 - accuracy: 0.9069 - val_loss: 3.1947 - val_accuracy: 0.5065 - 2s/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "391/391 - 1s - loss: 0.2190 - accuracy: 0.9241 - val_loss: 3.1759 - val_accuracy: 0.5157 - 1s/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "391/391 - 2s - loss: 0.2154 - accuracy: 0.9243 - val_loss: 3.3123 - val_accuracy: 0.5156 - 2s/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "391/391 - 1s - loss: 0.2056 - accuracy: 0.9293 - val_loss: 3.3742 - val_accuracy: 0.5070 - 1s/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "391/391 - 1s - loss: 0.2314 - accuracy: 0.9182 - val_loss: 3.4272 - val_accuracy: 0.5028 - 1s/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "391/391 - 2s - loss: 0.1931 - accuracy: 0.9329 - val_loss: 3.5537 - val_accuracy: 0.5107 - 2s/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "391/391 - 1s - loss: 0.2140 - accuracy: 0.9235 - val_loss: 3.4046 - val_accuracy: 0.5048 - 1s/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "391/391 - 1s - loss: 0.2083 - accuracy: 0.9259 - val_loss: 3.5065 - val_accuracy: 0.5114 - 1s/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "391/391 - 2s - loss: 0.1936 - accuracy: 0.9317 - val_loss: 3.5133 - val_accuracy: 0.5110 - 2s/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "391/391 - 2s - loss: 0.1843 - accuracy: 0.9351 - val_loss: 3.5132 - val_accuracy: 0.5077 - 2s/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "391/391 - 1s - loss: 0.1709 - accuracy: 0.9407 - val_loss: 3.7100 - val_accuracy: 0.4927 - 1s/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "391/391 - 1s - loss: 0.2140 - accuracy: 0.9258 - val_loss: 3.6512 - val_accuracy: 0.5088 - 1s/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "391/391 - 1s - loss: 0.1827 - accuracy: 0.9362 - val_loss: 3.7609 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "391/391 - 1s - loss: 0.1781 - accuracy: 0.9372 - val_loss: 3.6402 - val_accuracy: 0.5063 - 1s/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "391/391 - 1s - loss: 0.1772 - accuracy: 0.9376 - val_loss: 3.6580 - val_accuracy: 0.5113 - 1s/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "391/391 - 2s - loss: 0.1837 - accuracy: 0.9355 - val_loss: 3.8103 - val_accuracy: 0.5142 - 2s/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "391/391 - 1s - loss: 0.1651 - accuracy: 0.9425 - val_loss: 3.7633 - val_accuracy: 0.5166 - 1s/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "391/391 - 1s - loss: 0.1840 - accuracy: 0.9367 - val_loss: 3.7981 - val_accuracy: 0.5048 - 1s/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "391/391 - 1s - loss: 0.1581 - accuracy: 0.9445 - val_loss: 3.8771 - val_accuracy: 0.5066 - 1s/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "391/391 - 1s - loss: 0.1713 - accuracy: 0.9399 - val_loss: 3.8844 - val_accuracy: 0.5102 - 1s/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "391/391 - 1s - loss: 0.1371 - accuracy: 0.9525 - val_loss: 4.0087 - val_accuracy: 0.5176 - 1s/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "391/391 - 2s - loss: 0.1960 - accuracy: 0.9315 - val_loss: 3.8203 - val_accuracy: 0.4990 - 2s/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "391/391 - 1s - loss: 0.1398 - accuracy: 0.9530 - val_loss: 3.9469 - val_accuracy: 0.5036 - 1s/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "391/391 - 2s - loss: 0.1797 - accuracy: 0.9377 - val_loss: 3.8089 - val_accuracy: 0.5143 - 2s/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "391/391 - 2s - loss: 0.1323 - accuracy: 0.9541 - val_loss: 4.0593 - val_accuracy: 0.5106 - 2s/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "391/391 - 1s - loss: 0.1269 - accuracy: 0.9563 - val_loss: 4.0188 - val_accuracy: 0.5132 - 1s/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "391/391 - 2s - loss: 0.1584 - accuracy: 0.9447 - val_loss: 4.1373 - val_accuracy: 0.5137 - 2s/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "391/391 - 2s - loss: 0.1389 - accuracy: 0.9523 - val_loss: 4.1872 - val_accuracy: 0.4930 - 2s/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "391/391 - 1s - loss: 0.1899 - accuracy: 0.9350 - val_loss: 4.1241 - val_accuracy: 0.5074 - 1s/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "391/391 - 1s - loss: 0.1209 - accuracy: 0.9590 - val_loss: 4.1593 - val_accuracy: 0.5117 - 1s/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "391/391 - 1s - loss: 0.1530 - accuracy: 0.9486 - val_loss: 4.0657 - val_accuracy: 0.5126 - 1s/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "391/391 - 1s - loss: 0.1585 - accuracy: 0.9446 - val_loss: 4.0422 - val_accuracy: 0.5137 - 1s/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "391/391 - 2s - loss: 0.1125 - accuracy: 0.9609 - val_loss: 4.1986 - val_accuracy: 0.5055 - 2s/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "391/391 - 1s - loss: 0.1098 - accuracy: 0.9626 - val_loss: 4.3159 - val_accuracy: 0.5164 - 1s/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "391/391 - 2s - loss: 0.1839 - accuracy: 0.9361 - val_loss: 4.1448 - val_accuracy: 0.5038 - 2s/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "391/391 - 2s - loss: 0.1099 - accuracy: 0.9633 - val_loss: 4.2345 - val_accuracy: 0.5137 - 2s/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "391/391 - 2s - loss: 0.1404 - accuracy: 0.9519 - val_loss: 4.2862 - val_accuracy: 0.5153 - 2s/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "391/391 - 2s - loss: 0.1286 - accuracy: 0.9555 - val_loss: 4.4409 - val_accuracy: 0.5098 - 2s/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "391/391 - 1s - loss: 0.0908 - accuracy: 0.9696 - val_loss: 4.2442 - val_accuracy: 0.5096 - 1s/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "391/391 - 1s - loss: 0.1848 - accuracy: 0.9360 - val_loss: 4.2166 - val_accuracy: 0.5107 - 1s/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "391/391 - 1s - loss: 0.1302 - accuracy: 0.9564 - val_loss: 4.3943 - val_accuracy: 0.5052 - 1s/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "391/391 - 1s - loss: 0.1385 - accuracy: 0.9522 - val_loss: 4.2122 - val_accuracy: 0.5056 - 1s/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "391/391 - 1s - loss: 0.0932 - accuracy: 0.9683 - val_loss: 4.4095 - val_accuracy: 0.5114 - 1s/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "391/391 - 2s - loss: 0.1129 - accuracy: 0.9623 - val_loss: 4.4145 - val_accuracy: 0.5089 - 2s/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "391/391 - 2s - loss: 0.0969 - accuracy: 0.9674 - val_loss: 4.5367 - val_accuracy: 0.5079 - 2s/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "391/391 - 1s - loss: 0.1359 - accuracy: 0.9533 - val_loss: 4.4439 - val_accuracy: 0.5007 - 1s/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "391/391 - 1s - loss: 0.1356 - accuracy: 0.9534 - val_loss: 4.4709 - val_accuracy: 0.5051 - 1s/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "391/391 - 1s - loss: 0.1043 - accuracy: 0.9650 - val_loss: 4.6983 - val_accuracy: 0.5067 - 1s/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "391/391 - 1s - loss: 0.1221 - accuracy: 0.9574 - val_loss: 4.5523 - val_accuracy: 0.5107 - 1s/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "391/391 - 1s - loss: 0.1061 - accuracy: 0.9652 - val_loss: 4.6105 - val_accuracy: 0.4983 - 1s/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "391/391 - 1s - loss: 0.1255 - accuracy: 0.9565 - val_loss: 4.5320 - val_accuracy: 0.5111 - 1s/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "391/391 - 1s - loss: 0.1058 - accuracy: 0.9646 - val_loss: 4.7969 - val_accuracy: 0.5050 - 1s/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "391/391 - 2s - loss: 0.1302 - accuracy: 0.9557 - val_loss: 4.5717 - val_accuracy: 0.5097 - 2s/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "391/391 - 2s - loss: 0.1078 - accuracy: 0.9636 - val_loss: 4.5961 - val_accuracy: 0.5090 - 2s/epoch - 4ms/step\n",
            "Epoch 138/200\n",
            "391/391 - 2s - loss: 0.0690 - accuracy: 0.9769 - val_loss: 4.7587 - val_accuracy: 0.4970 - 2s/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "391/391 - 1s - loss: 0.1364 - accuracy: 0.9536 - val_loss: 4.4953 - val_accuracy: 0.5085 - 1s/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "391/391 - 2s - loss: 0.1057 - accuracy: 0.9651 - val_loss: 4.6647 - val_accuracy: 0.5067 - 2s/epoch - 4ms/step\n",
            "Epoch 141/200\n",
            "391/391 - 2s - loss: 0.1120 - accuracy: 0.9621 - val_loss: 4.6528 - val_accuracy: 0.4969 - 2s/epoch - 4ms/step\n",
            "Epoch 142/200\n",
            "391/391 - 1s - loss: 0.0900 - accuracy: 0.9709 - val_loss: 4.7354 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "391/391 - 1s - loss: 0.0838 - accuracy: 0.9729 - val_loss: 4.6363 - val_accuracy: 0.5058 - 1s/epoch - 4ms/step\n",
            "Epoch 144/200\n",
            "391/391 - 1s - loss: 0.1540 - accuracy: 0.9491 - val_loss: 4.7406 - val_accuracy: 0.5132 - 1s/epoch - 4ms/step\n",
            "Epoch 145/200\n",
            "391/391 - 1s - loss: 0.0651 - accuracy: 0.9788 - val_loss: 4.7722 - val_accuracy: 0.5048 - 1s/epoch - 4ms/step\n",
            "Epoch 146/200\n",
            "391/391 - 2s - loss: 0.1747 - accuracy: 0.9422 - val_loss: 4.5821 - val_accuracy: 0.5097 - 2s/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "391/391 - 1s - loss: 0.0584 - accuracy: 0.9817 - val_loss: 4.7110 - val_accuracy: 0.5150 - 1s/epoch - 4ms/step\n",
            "Epoch 148/200\n",
            "391/391 - 2s - loss: 0.0733 - accuracy: 0.9761 - val_loss: 4.8544 - val_accuracy: 0.4980 - 2s/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "391/391 - 1s - loss: 0.1442 - accuracy: 0.9515 - val_loss: 4.8837 - val_accuracy: 0.5101 - 1s/epoch - 4ms/step\n",
            "Epoch 150/200\n",
            "391/391 - 1s - loss: 0.0540 - accuracy: 0.9824 - val_loss: 4.7982 - val_accuracy: 0.5114 - 1s/epoch - 4ms/step\n",
            "Epoch 151/200\n",
            "391/391 - 2s - loss: 0.1155 - accuracy: 0.9618 - val_loss: 4.9457 - val_accuracy: 0.5017 - 2s/epoch - 4ms/step\n",
            "Epoch 152/200\n",
            "391/391 - 2s - loss: 0.1286 - accuracy: 0.9567 - val_loss: 4.6562 - val_accuracy: 0.5074 - 2s/epoch - 4ms/step\n",
            "Epoch 153/200\n",
            "391/391 - 2s - loss: 0.0639 - accuracy: 0.9791 - val_loss: 4.9269 - val_accuracy: 0.5154 - 2s/epoch - 4ms/step\n",
            "Epoch 154/200\n",
            "391/391 - 1s - loss: 0.0950 - accuracy: 0.9689 - val_loss: 4.8828 - val_accuracy: 0.5082 - 1s/epoch - 3ms/step\n",
            "Epoch 155/200\n",
            "391/391 - 1s - loss: 0.0957 - accuracy: 0.9678 - val_loss: 4.9107 - val_accuracy: 0.5141 - 1s/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "391/391 - 1s - loss: 0.0466 - accuracy: 0.9855 - val_loss: 5.1177 - val_accuracy: 0.5069 - 1s/epoch - 4ms/step\n",
            "Epoch 157/200\n",
            "391/391 - 2s - loss: 0.1574 - accuracy: 0.9482 - val_loss: 4.7855 - val_accuracy: 0.5022 - 2s/epoch - 4ms/step\n",
            "Epoch 158/200\n",
            "391/391 - 1s - loss: 0.0785 - accuracy: 0.9739 - val_loss: 5.0819 - val_accuracy: 0.5104 - 1s/epoch - 4ms/step\n",
            "Epoch 159/200\n",
            "391/391 - 2s - loss: 0.0937 - accuracy: 0.9693 - val_loss: 4.9808 - val_accuracy: 0.5121 - 2s/epoch - 4ms/step\n",
            "Epoch 160/200\n",
            "391/391 - 1s - loss: 0.0949 - accuracy: 0.9682 - val_loss: 5.0000 - val_accuracy: 0.5072 - 1s/epoch - 4ms/step\n",
            "Epoch 161/200\n",
            "391/391 - 2s - loss: 0.0738 - accuracy: 0.9760 - val_loss: 4.9583 - val_accuracy: 0.5118 - 2s/epoch - 4ms/step\n",
            "Epoch 162/200\n",
            "391/391 - 2s - loss: 0.0741 - accuracy: 0.9750 - val_loss: 5.1070 - val_accuracy: 0.4982 - 2s/epoch - 4ms/step\n",
            "Epoch 163/200\n",
            "391/391 - 2s - loss: 0.0937 - accuracy: 0.9688 - val_loss: 5.0597 - val_accuracy: 0.5095 - 2s/epoch - 4ms/step\n",
            "Epoch 164/200\n",
            "391/391 - 1s - loss: 0.0622 - accuracy: 0.9793 - val_loss: 5.0380 - val_accuracy: 0.5120 - 1s/epoch - 4ms/step\n",
            "Epoch 165/200\n",
            "391/391 - 1s - loss: 0.1611 - accuracy: 0.9481 - val_loss: 4.8799 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "391/391 - 1s - loss: 0.0514 - accuracy: 0.9826 - val_loss: 5.1624 - val_accuracy: 0.5125 - 1s/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "391/391 - 1s - loss: 0.0470 - accuracy: 0.9847 - val_loss: 5.2767 - val_accuracy: 0.5132 - 1s/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "391/391 - 2s - loss: 0.1315 - accuracy: 0.9564 - val_loss: 4.9919 - val_accuracy: 0.5017 - 2s/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "391/391 - 2s - loss: 0.0902 - accuracy: 0.9698 - val_loss: 4.9760 - val_accuracy: 0.5082 - 2s/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "391/391 - 1s - loss: 0.0452 - accuracy: 0.9858 - val_loss: 5.1699 - val_accuracy: 0.5095 - 1s/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "391/391 - 2s - loss: 0.1107 - accuracy: 0.9635 - val_loss: 5.1935 - val_accuracy: 0.5087 - 2s/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "391/391 - 1s - loss: 0.1041 - accuracy: 0.9652 - val_loss: 5.0435 - val_accuracy: 0.5127 - 1s/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "391/391 - 2s - loss: 0.0337 - accuracy: 0.9902 - val_loss: 5.0686 - val_accuracy: 0.5121 - 2s/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "391/391 - 1s - loss: 0.0758 - accuracy: 0.9755 - val_loss: 5.3574 - val_accuracy: 0.4944 - 1s/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "391/391 - 1s - loss: 0.0961 - accuracy: 0.9683 - val_loss: 5.0901 - val_accuracy: 0.5113 - 1s/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "391/391 - 2s - loss: 0.0532 - accuracy: 0.9825 - val_loss: 5.2583 - val_accuracy: 0.5019 - 2s/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "391/391 - 2s - loss: 0.1359 - accuracy: 0.9556 - val_loss: 5.1043 - val_accuracy: 0.4995 - 2s/epoch - 5ms/step\n",
            "Epoch 178/200\n",
            "391/391 - 2s - loss: 0.0776 - accuracy: 0.9746 - val_loss: 5.0916 - val_accuracy: 0.5104 - 2s/epoch - 5ms/step\n",
            "Epoch 179/200\n",
            "391/391 - 2s - loss: 0.0512 - accuracy: 0.9840 - val_loss: 5.2253 - val_accuracy: 0.5077 - 2s/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "391/391 - 1s - loss: 0.0895 - accuracy: 0.9711 - val_loss: 5.0821 - val_accuracy: 0.5043 - 1s/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "391/391 - 1s - loss: 0.0868 - accuracy: 0.9711 - val_loss: 5.1546 - val_accuracy: 0.5131 - 1s/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "391/391 - 1s - loss: 0.0904 - accuracy: 0.9703 - val_loss: 5.3692 - val_accuracy: 0.5063 - 1s/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "391/391 - 1s - loss: 0.0960 - accuracy: 0.9685 - val_loss: 5.1595 - val_accuracy: 0.5221 - 1s/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "391/391 - 1s - loss: 0.0277 - accuracy: 0.9921 - val_loss: 5.3511 - val_accuracy: 0.5106 - 1s/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "391/391 - 1s - loss: 0.1120 - accuracy: 0.9638 - val_loss: 5.1701 - val_accuracy: 0.5103 - 1s/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "391/391 - 2s - loss: 0.0680 - accuracy: 0.9779 - val_loss: 5.1529 - val_accuracy: 0.5147 - 2s/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "391/391 - 1s - loss: 0.0667 - accuracy: 0.9781 - val_loss: 5.4110 - val_accuracy: 0.5111 - 1s/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "391/391 - 1s - loss: 0.0978 - accuracy: 0.9673 - val_loss: 5.2780 - val_accuracy: 0.5073 - 1s/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "391/391 - 1s - loss: 0.0509 - accuracy: 0.9829 - val_loss: 5.3340 - val_accuracy: 0.5163 - 1s/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "391/391 - 1s - loss: 0.0212 - accuracy: 0.9938 - val_loss: 5.5432 - val_accuracy: 0.5034 - 1s/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "391/391 - 2s - loss: 0.1605 - accuracy: 0.9504 - val_loss: 5.1043 - val_accuracy: 0.5026 - 2s/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "391/391 - 2s - loss: 0.0665 - accuracy: 0.9778 - val_loss: 5.3597 - val_accuracy: 0.5135 - 2s/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "391/391 - 2s - loss: 0.0253 - accuracy: 0.9928 - val_loss: 5.4488 - val_accuracy: 0.5190 - 2s/epoch - 4ms/step\n",
            "Epoch 194/200\n",
            "391/391 - 2s - loss: 0.0916 - accuracy: 0.9724 - val_loss: 5.1444 - val_accuracy: 0.5086 - 2s/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "391/391 - 2s - loss: 0.1159 - accuracy: 0.9636 - val_loss: 5.1055 - val_accuracy: 0.5215 - 2s/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "391/391 - 2s - loss: 0.0237 - accuracy: 0.9931 - val_loss: 5.4381 - val_accuracy: 0.5063 - 2s/epoch - 4ms/step\n",
            "Epoch 197/200\n",
            "391/391 - 1s - loss: 0.0945 - accuracy: 0.9698 - val_loss: 5.4144 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "391/391 - 1s - loss: 0.0799 - accuracy: 0.9739 - val_loss: 5.1680 - val_accuracy: 0.5224 - 1s/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "391/391 - 2s - loss: 0.0558 - accuracy: 0.9822 - val_loss: 5.7015 - val_accuracy: 0.4987 - 2s/epoch - 4ms/step\n",
            "Epoch 200/200\n",
            "391/391 - 2s - loss: 0.0594 - accuracy: 0.9811 - val_loss: 5.3294 - val_accuracy: 0.5212 - 2s/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3e1161a10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 어떤 Hyper-parameter setting에서 최고의 성능이 나왔나요?\n",
        "# evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print(\"Loss : %.4f, Test Accuracy : %.4f\" % (loss, acc))"
      ],
      "metadata": {
        "id": "mb0Z9y8RkAUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b13353-a4d4-494a-c023-ada0f706940d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 3ms/step - loss: 5.3294 - accuracy: 0.5212\n",
            "Loss : 5.3294, Test Accuracy : 0.5212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ql0zhEsf9wo1"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}